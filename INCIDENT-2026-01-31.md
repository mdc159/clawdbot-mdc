# Incident Report: EC2 SSH Lockout & Recovery

**Date**: 2026-01-31
**Duration**: ~3 hours
**Severity**: Critical (complete loss of SSH access)

## Summary

Attempted to harden EC2 security by changing SSH port from 22 to 2222. Misconfigured systemd socket override broke SSH completely, locking us out of the instance.

---

## What Happened (Timeline)

### 1. Security Hardening Attempt
- Installed fail2ban (worked fine)
- Installed UFW firewall (worked fine)
- Attempted to change SSH from port 22 to 2222

### 2. The Fatal Mistake
Created a systemd socket override that was malformed:
```bash
# WRONG - This broke everything
sudo mkdir -p /etc/systemd/system/ssh.socket.d
sudo tee /etc/systemd/system/ssh.socket.d/override.conf <<EOF
[Socket]
ListenStream=
ListenStream=2222
EOF
```

**Why it broke**: Ubuntu 24.04 uses systemd socket activation for SSH. The override file syntax or interaction with existing config caused SSH to fail completely on restart. Neither port 22 nor 2222 worked.

### 3. Compounding Problems
- **No Elastic IP**: Instance had a dynamic public IP that changed on every reboot
- **No password set**: ubuntu user had no password, only key-based auth
- **Serial Console unusable**: Requires password authentication, which wasn't configured
- **User-data doesn't re-run**: Only executes on FIRST boot, not reboots

---

## Recovery Attempts (What Failed)

### Attempt 1: User-Data Script
Created fix script and added as user-data:
```bash
#!/bin/bash
echo ubuntu:TempPass123! | chpasswd
rm -f /etc/systemd/system/ssh.socket.d/override.conf
sed -i 's/^Port 2222/Port 22/' /etc/ssh/sshd_config
systemctl daemon-reload
systemctl restart ssh.socket
systemctl restart ssh
```
**Result**: Failed. User-data only runs on first boot, not subsequent reboots.

### Attempt 2: Serial Console
Tried to access via AWS Serial Console.
**Result**: Failed. Login prompt appeared but no password was set for ubuntu user.

### Attempt 3: cloud-init clean + reboot
Hoped forcing cloud-init to re-run would execute user-data.
**Result**: Failed. Still didn't execute the user-data script.

---

## What Actually Worked: EBS Volume Swap

1. **Launched helper instance** (t3.micro with same key pair)
2. **Stopped broken instance** (not terminate!)
3. **Detached root volume** from broken instance
4. **Attached volume to helper** as `/dev/sdf`
5. **Mounted and fixed** on helper:
   ```bash
   sudo mkdir /mnt/broken
   sudo mount /dev/xvdf1 /mnt/broken
   sudo rm /mnt/broken/etc/systemd/system/ssh.socket.d/override.conf
   sudo sed -i 's/^Port 2222/Port 22/' /mnt/broken/etc/ssh/sshd_config
   sudo umount /mnt/broken
   ```
6. **Detached from helper**, reattached to original as `/dev/sda1`
7. **Started original instance** - SSH worked!

### Post-Recovery
- **Allocated Elastic IP** (3.131.112.190) so IP stops changing
- **Terminated helper instance**
- **Updated all documentation** with new IP

---

## Lessons Learned

### DO NOT
1. **Never change SSH port via systemd socket override** on Ubuntu 22.04+
   - If you must change ports, edit `/etc/ssh/sshd_config` directly AND update the socket
   - Test with a second SSH session open before disconnecting

2. **Never rely on user-data for recovery**
   - It only runs on FIRST boot
   - Even `cloud-init clean` doesn't reliably re-trigger it

3. **Never harden SSH without a backup access method**
   - Set a password BEFORE making SSH changes
   - Or have Serial Console access ready
   - Or use AWS Systems Manager Session Manager

4. **Never run instances without Elastic IP** if you need stable access
   - Dynamic IPs change on every stop/start
   - Makes recovery much harder

### ALWAYS DO
1. **Allocate Elastic IP first** for any instance you care about
2. **Set ubuntu password** before any SSH changes:
   ```bash
   sudo passwd ubuntu
   ```
3. **Keep a second SSH session open** when changing SSH config
4. **Test changes** before closing your working session
5. **Have EBS volume swap procedure documented** (it's the nuclear option that works)

---

## Current State (Post-Recovery)

| Item | Value |
|------|-------|
| Elastic IP | 3.131.112.190 |
| SSH Port | 22 (standard) |
| SSH Access | `ssh moltbot-ec2` |
| UFW Ports | 22, 2222, 18789 |
| fail2ban | Active |
| ubuntu password | **NOT SET** |
| Docker | Running (moltbot container) |

---

## Still Broken

1. **ubuntu user has no sudo password set**
   - Key-based sudo works but password sudo doesn't
   - Can't install Homebrew (needs sudo password)
   - Need to fix via: `sudo passwd ubuntu`

   **Wait** - if we can SSH in with key, we can run `sudo passwd ubuntu` because key-based sudo is passwordless!

---

## Fix Remaining Issue

SSH in and set a password:
```bash
ssh moltbot-ec2
sudo passwd ubuntu
# Enter new password twice
```

Then Homebrew install will work.

---

## Files Modified During Incident

- `/etc/systemd/system/ssh.socket.d/override.conf` - DELETED (was the problem)
- `/etc/ssh/sshd_config` - Reverted to Port 22
- Security Group - Ports 22, 2222, 18789 allowed
- Elastic IP 3.131.112.190 allocated and associated

---

## References

- AWS EBS Volume Detach/Attach: https://docs.aws.amazon.com/ebs/latest/userguide/ebs-detaching-volume.html
- Ubuntu SSH Socket Activation: https://discourse.ubuntu.com/t/sshd-now-uses-socket-based-activation-ubuntu-22-10-and-later/30189
- EC2 Serial Console: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-serial-console.html
